Automatically generated by Mendeley Desktop 1.17.9
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Chen2016b,
abstract = {Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end- to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quan- tile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compres- sion and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems.},
archivePrefix = {arXiv},
arxivId = {1603.02754},
author = {Chen, Tianqi and Guestrin, Carlos},
doi = {10.1145/2939672.2939785},
eprint = {1603.02754},
file = {:E$\backslash$:/paper/mendeley/Chen, Guestrin - 2016 - XGBoost Reliable Large-scale Tree Boosting System.pdf:pdf},
isbn = {9781450342322},
issn = {0146-4833},
journal = {arXiv},
keywords = {large-scale machine learning},
pages = {1--6},
title = {{XGBoost : Reliable Large-scale Tree Boosting System}},
year = {2016}
}
@article{Statistics2017b,
author = {Statistics, Mathematical},
file = {:E$\backslash$:/paper/mendeley/Statistics - 2017 - Greedy Function Approximation A Gradient Boosting Machine Author ( s ) Jerome H . Friedman Source The Annals of St.pdf:pdf},
number = {5},
pages = {1189--1232},
title = {{Greedy Function Approximation : A Gradient Boosting Machine Author ( s ): Jerome H . Friedman Source : The Annals of Statistics , Vol . 29 , No . 5 ( Oct ., 2001 ), pp . 1189-1232 Published by : Institute of Mathematical Statistics Stable URL : http://www}},
volume = {29},
year = {2017}
}
@article{Schapire1999b,
abstract = {Boosting is a general method for improving the accuracy of any given learning algorithm. This short overview paper introduces the boosting algorithm AdaBoost, and explains the underlying theory of boosting, including an explanation of why boosting often does not suffer from overfitting as well as boosting's relationship to support-vector machines. Some examples of recent applications of boosting are also described.},
archivePrefix = {arXiv},
arxivId = {arXiv:1508.01136v1},
author = {Schapire, Robert E.},
doi = {citeulike-article-id:765005},
eprint = {arXiv:1508.01136v1},
file = {:E$\backslash$:/paper/mendeley/Schapire - 1999 - A brief introduction to boosting.pdf:pdf},
isbn = {3540440119},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
number = {5},
pages = {1401--1406},
title = {{A brief introduction to boosting}},
volume = {2},
year = {1999}
}
@misc{Chen2015b,
abstract = {The discovery of the Higgs boson is remarkable for its importance in modern Physics research. The next step for physicists is to discover more about the Higgs boson from the data of the Large Hadron Collider (LHC). A fundamental and challenging task is to extract the signal of Higgs boson from background noises. The machine learning technique is one important component in solving this problem. In this paper, we propose to solve the Higgs boson classification problem with a gradient boosting approach. Our model learns ensemble of boosted trees that makes careful tradeoff between classification error and model complexity. Physical meaningful features are further extracted to improve the classification accuracy. Our final solution obtained an AMS of 3.71885 on the private leaderboard, making us the top 2{\%} in the Higgs boson challenge.},
author = {Chen, Tianqi and He, Tong},
booktitle = {JMLR: Workshop and Conference Proceedings},
file = {:E$\backslash$:/paper/mendeley/Chen, He - 2015 - Higgs Boson Discovery with Boosted Trees.pdf:pdf},
keywords = {Gradient Boosting,Higgs Boson,Machine Learning},
number = {May 2014},
pages = {69--80},
title = {{Higgs Boson Discovery with Boosted Trees}},
volume = {42},
year = {2015}
}
@article{Valiant1984b,
abstract = {Humans appear to be able to learn new concepts without needing to be programmed explicitly in any conventional sense. In this paper we regard learning as the phenomenon of knowledge acquisition in the absence of explicit programming. We give a precise methodology for studying this phenomenon from a computational viewpoint. It consists of choosing an appropriate information gathering mechanism, the learning protocol, and exploring the class of concepts that can be learned using it in a reasonable (polynomial) number of steps. Although inherent algorithmic complexity appears to set serious limits to the range of concepts that can be learned, we show that there are some important nontrivial classes of propositional concepts that can be learned in a realistic sense.},
author = {Valiant, L. G.},
doi = {10.1145/1968.1972},
file = {:E$\backslash$:/paper/mendeley/Valiant - 1984 - A theory of the learnable.pdf:pdf},
isbn = {0897911334},
issn = {00010782},
journal = {Communications of the ACM},
number = {11},
pages = {1134--1142},
pmid = {12929239},
title = {{A theory of the learnable}},
volume = {27},
year = {1984}
}
